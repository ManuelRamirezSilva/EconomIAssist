#!/usr/bin/env python3
"""
Agente Conversacional Modular - OpenAI Agents SDK con MCP Real
ImplementaciÃ³n completa con conexiÃ³n real a servidores MCP externos
"""

import asyncio
import os
import sys
import json
import warnings
from typing import Dict, List, Optional, Any
from dataclasses import dataclass
import structlog
from dotenv import load_dotenv

# Suprimir warnings de tracing del OpenAI SDK
warnings.filterwarnings("ignore")
os.environ["OPENAI_LOG_LEVEL"] = "ERROR"

# Forzar recarga de variables de entorno
for key in list(os.environ.keys()):
    if key.startswith('AZURE_OPENAI_') or key.startswith('TAVILY_'):
        del os.environ[key]

# Cargar variables de entorno
env_path = os.path.join(os.path.dirname(__file__), '..', '..', '.env')
load_dotenv(env_path, override=True)

# OpenAI Agents SDK imports
from agents import Agent, Runner
from agents.models.openai_chatcompletions import OpenAIChatCompletionsModel
from openai import AsyncAzureOpenAI

# Importar cliente MCP real
from .mcp_client import MCPManager

# Configurar logging estructurado
logger = structlog.get_logger()

# Suprimir logs de OpenAI durante ejecuciÃ³n
import logging
logging.getLogger("openai").setLevel(logging.ERROR)
logging.getLogger("httpx").setLevel(logging.ERROR)

@dataclass
class MCPServerConfig:
    """ConfiguraciÃ³n de un servidor MCP"""
    name: str
    path: str
    description: str
    capabilities: List[str]

class AzureOpenAIConfig:
    """ConfiguraciÃ³n para Azure OpenAI"""
    
    def __init__(self):
        self.api_base = os.getenv("AZURE_OPENAI_API_BASE")
        self.api_key = os.getenv("AZURE_OPENAI_API_KEY")
        self.api_version = os.getenv("AZURE_OPENAI_API_VERSION")
        self.deployment_name = os.getenv("AZURE_OPENAI_DEPLOYMENT_NAME")
        
        if not all([self.api_base, self.api_key, self.api_version, self.deployment_name]):
            raise ValueError("Faltan credenciales de Azure OpenAI en el archivo .env")
        
        print(f"âœ… Azure OpenAI configurado:")
        print(f"   ğŸ“ Endpoint: {self.api_base}")
        print(f"   ğŸ¤– Deployment: {self.deployment_name}")
        print(f"   ğŸ”‘ API Version: {self.api_version}")
    
    def create_client(self) -> AsyncAzureOpenAI:
        """Crea un cliente de Azure OpenAI"""
        return AsyncAzureOpenAI(
            azure_endpoint=self.api_base,
            api_key=self.api_key,
            api_version=self.api_version
        )
    
    def create_model(self) -> OpenAIChatCompletionsModel:
        """Crea un modelo OpenAI configurado para Azure"""
        client = self.create_client()
        return OpenAIChatCompletionsModel(
            model=self.deployment_name,  # Usar deployment name correcto
            openai_client=client
        )

class IntentClassifier: ###MAXI WORK HERE
    """Clasificador de intenciones usando NLP para routing"""
    
    INTENT_PATTERNS = {
        'financial_query': [
            'saldo', 'dinero', 'cuenta', 'balance', 'cuanto tengo',
            'estado financiero', 'resumen'
        ],
        'financial_action': [
            'registra', 'anota', 'guarda', 'gasto', 'ingreso', 
            'transaccion', 'pago', 'compra'
        ],
        'rag_query': [
            'consejo', 'como', 'que es', 'explicame', 'ayuda con',
            'informacion', 'aprende', 'enseÃ±ame'
        ],
        'help': [
            'ayuda', 'help', 'que puedes hacer', 'comandos', 'funciones'
        ],
        'multi_intent': [
            'y tambien', 'ademas', 'despues', 'luego'
        ]
    }
    
    def classify_intent(self, text: str) -> Dict[str, float]:
        """
        Clasifica intenciones con scores de confianza
        Retorna un diccionario con intenciÃ³n -> score
        """
        text_lower = text.lower()
        scores = {}
        
        for intent, keywords in self.INTENT_PATTERNS.items():
            score = 0.0
            for keyword in keywords:
                if keyword in text_lower:
                    score += 1.0
            
            # Normalizar por nÃºmero de keywords
            if keywords:
                scores[intent] = score / len(keywords)
        
        # Determinar intenciÃ³n principal
        if not scores or max(scores.values()) == 0:
            scores['general'] = 1.0
        
        return scores
    
    def get_primary_intent(self, text: str) -> str:
        """Obtiene la intenciÃ³n principal"""
        scores = self.classify_intent(text)
        return max(scores.items(), key=lambda x: x[1])[0]

class CapabilityDiscovery:
    """Discovery automÃ¡tico de capacidades MCP"""
    
    def __init__(self):
        self.server_configs = [
            MCPServerConfig(
                name="financial",
                path="src/mcp_server/server.py",
                description="GestiÃ³n financiera: transacciones, saldos, resÃºmenes",
                capabilities=["registrar_transaccion", "obtener_saldo", "obtener_transacciones"]
            ),
            MCPServerConfig(
                name="rag",
                path="src/mcp_server/rag_server.py", 
                description="RecuperaciÃ³n de informaciÃ³n y consejos financieros",
                capabilities=["buscar_informacion", "expandir_contexto", "generar_respuesta_contextual"]
            )
        ]
        self.available_servers = {}
    
    async def discover_and_validate(self) -> Dict[str, MCPServerConfig]:
        """Descubre y valida servidores MCP disponibles"""
        print("ğŸ” Iniciando discovery de servidores MCP...")
        
        available = {}
        for config in self.server_configs:
            if os.path.exists(config.path):
                # Para la demo, asumimos que estÃ¡n disponibles si el archivo existe
                available[config.name] = config
                print(f"âœ… Servidor encontrado: {config.name}")
            else:
                print(f"âŒ Servidor no encontrado: {config.path}")
        
        self.available_servers = available
        return available

class RoutingEngine:
    """Motor de enrutamiento inteligente con fallbacks"""
    
    def __init__(self, discovery: CapabilityDiscovery):
        self.discovery = discovery
        self.intent_to_server = {
            'financial_query': ['financial'],
            'financial_action': ['financial'],
            'rag_query': ['rag', 'financial'],  # Fallback a financial si RAG no estÃ¡ disponible
            'general': ['rag', 'financial'],   # Intentar RAG primero, luego financial
            'help': None  # Manejado localmente
        }
    
    def route_intent(self, intent: str) -> Optional[str]:
        """
        Enruta una intenciÃ³n al servidor apropiado con fallbacks
        """
        server_preferences = self.intent_to_server.get(intent, ['financial'])
        
        if server_preferences is None:
            return None
        
        # Buscar el primer servidor disponible en orden de preferencia
        available_servers = self.discovery.available_servers
        for server_name in server_preferences:
            if server_name in available_servers:
                return server_name
        
        # Fallback final a financial si estÃ¡ disponible
        if 'financial' in available_servers:
            return 'financial'
        
        return None

class MemoryManager:
    """Manejo de memoria semÃ¡ntica y contexto conversacional"""
    
    def __init__(self):
        self.conversation_history = []
        self.context_cache = {}
        self.max_history = 10
    
    def add_interaction(self, user_input: str, agent_response: str, metadata: Dict[str, Any]):
        """AÃ±ade una interacciÃ³n a la memoria"""
        interaction = {
            'timestamp': asyncio.get_event_loop().time(),
            'user_input': user_input,
            'agent_response': agent_response,
            'metadata': metadata
        }
        
        self.conversation_history.append(interaction)
        
        # Mantener solo las Ãºltimas N interacciones
        if len(self.conversation_history) > self.max_history:
            self.conversation_history = self.conversation_history[-self.max_history:]
    
    def get_context_summary(self) -> str:
        """Genera un resumen del contexto conversacional"""
        if not self.conversation_history:
            return "Primera interacciÃ³n del usuario."
        
        recent_interactions = self.conversation_history[-3:]  # Ãšltimas 3 interacciones
        summary = "Contexto reciente:\n"
        
        for i, interaction in enumerate(recent_interactions, 1):
            summary += f"{i}. Usuario: {interaction['user_input'][:100]}...\n"
            summary += f"   Respuesta: {interaction['agent_response'][:100]}...\n"
        
        return summary

class ConversationalAgent:
    """Agente conversacional con capacidades MCP reales"""
    
    def __init__(self):
        self.azure_client = None
        self.openai_model = None
        self.agent = None
        self.runner = None
        self.mcp_manager = None
        self.session_memory = []
        
    async def initialize(self):
        """Inicializa el agente y las conexiones MCP"""
        try:
            # Inicializar Azure OpenAI
            await self._setup_azure_openai()
            
            # Inicializar gestor MCP
            self.mcp_manager = MCPManager()
            
            # Conectar a servidores MCP
            await self._connect_mcp_servers()
            
            # Configurar agente con herramientas MCP
            await self._setup_agent_with_mcp()
            
            logger.info("âœ… Agente conversacional inicializado con MCP real")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Error inicializando agente: {e}")
            return False
    
    async def _connect_mcp_servers(self):
        """Conecta a todos los servidores MCP disponibles"""
        # Conectar a Tavily (bÃºsqueda web)
        tavily_connected = await self.mcp_manager.connect_tavily_server()
        if tavily_connected:
            logger.info("ğŸŒ Servidor Tavily MCP conectado")
        else:
            logger.warning("âš ï¸ No se pudo conectar al servidor Tavily MCP")
    
    async def _setup_agent_with_mcp(self):
        """Configura el agente con herramientas MCP disponibles"""
        # Obtener herramientas disponibles
        available_tools = await self.mcp_manager.get_available_tools()
        
        # Crear instrucciones del sistema que incluyan las capacidades MCP
        system_instructions = self._build_system_instructions(available_tools)
        
        # Crear agente
        self.agent = Agent(
            model=self.openai_model,
            instructions=system_instructions,
            name="EconomIAssist"
        )
        
        # Runner se usa como mÃ©todo estÃ¡tico, no se instancia
        self.runner = None

    def _build_system_instructions(self, available_tools: Dict[str, List[str]]) -> str:
        """Construye las instrucciones del sistema incluyendo capacidades MCP"""
        base_instructions = """Eres EconomIAssist, un asistente personal financiero inteligente.

CAPACIDADES PRINCIPALES:
1. ğŸ’° GestiÃ³n financiera personal
2. ğŸ§  Consejos de educaciÃ³n financiera  
3. ğŸ“Š AnÃ¡lisis de gastos e ingresos
4. ğŸŒ BÃºsqueda de informaciÃ³n financiera actualizada

PERSONALIDAD:
- Amigable y profesional
- Explicas conceptos financieros de manera simple
- Usas emojis para hacer la conversaciÃ³n mÃ¡s amena
- Siempre sugieres mejores prÃ¡cticas financieras"""

        # Agregar capacidades MCP disponibles
        if available_tools:
            mcp_capabilities = "\n\nCAPACIDADES MCP DISPONIBLES:\n"
            for server, tools in available_tools.items():
                mcp_capabilities += f"ğŸ”§ {server.upper()}: {', '.join(tools)}\n"
            
            mcp_capabilities += """
CUANDO USAR MCP:
- Si el usuario pregunta sobre informaciÃ³n financiera actual, usa bÃºsqueda web
- Si necesitas datos actualizados sobre mercados, inversiones, etc.
- Para obtener noticias financieras recientes
- Para buscar informaciÃ³n especÃ­fica que no tienes en tu base de conocimiento

IMPORTANTE: Cuando uses herramientas MCP, explica al usuario quÃ© estÃ¡s haciendo."""
            
            base_instructions += mcp_capabilities
        
        return base_instructions

    async def _setup_azure_openai(self):
        """Configura Azure OpenAI"""
        try:
            azure_config = AzureOpenAIConfig()
            self.azure_client = azure_config.create_client()
            self.openai_model = azure_config.create_model()
            logger.info("âœ… Azure OpenAI configurado correctamente")
        except Exception as e:
            logger.error(f"âŒ Error configurando Azure OpenAI: {e}")
            raise

    async def process_query(self, user_input: str) -> str:
        """Alias para process_user_input para compatibilidad"""
        return await self.process_user_input(user_input)

    async def process_user_input(self, user_input: str) -> str:
        """
        Procesa la entrada del usuario y devuelve la respuesta del agente.
        
        Args:
            user_input (str): La consulta del usuario
            
        Returns:
            str: La respuesta del agente
        """
        try:
            print(f"ğŸ¤– Procesando consulta: {user_input}")
            
            # Ejecutar consulta usando OpenAI Agents SDK
            result = await Runner.run(self.agent, user_input)
            response = result.final_output
            
            print(f"âœ… Respuesta generada ({len(response)} caracteres)")
            return response
            
        except Exception as e:
            error_msg = f"Error al procesar la consulta: {str(e)}"
            print(f"âŒ {error_msg}")
            return f"Lo siento, ocurriÃ³ un error al procesar tu consulta: {str(e)}"
    
    async def _analyze_if_needs_web_search(self, user_input: str) -> bool:
        """Analiza si la consulta necesita bÃºsqueda web"""
        web_keywords = [
            "actual", "actualizado", "reciente", "Ãºltimo", "Ãºltimas", "hoy", "2025",
            "mercado", "precio", "cotizaciÃ³n", "noticias", "tendencias", 
            "inversiÃ³n", "dÃ³lar", "bolsa", "acciones", "cripto"
        ]
        
        user_lower = user_input.lower()
        return any(keyword in user_lower for keyword in web_keywords)
    
    async def _extract_search_query(self, user_input: str) -> str:
        """Extrae una consulta de bÃºsqueda optimizada del input del usuario"""
        # SimplificaciÃ³n: extraer tÃ©rminos clave financieros
        financial_terms = []
        
        keywords = ["dÃ³lar", "euro", "bitcoin", "acciones", "mercado", "inversiÃ³n", 
                   "inflaciÃ³n", "tasas", "banco", "finanzas", "ahorro"]
        
        user_lower = user_input.lower()
        for keyword in keywords:
            if keyword in user_lower:
                financial_terms.append(keyword)
        
        if financial_terms:
            return f"{' '.join(financial_terms)} 2025 tendencias financieras"
        else:
            return f"{user_input} finanzas 2025"

    async def cleanup(self):
        """Limpia recursos al finalizar"""
        if self.mcp_manager:
            await self.mcp_manager.disconnect_all()
        logger.info("ğŸ§¹ Recursos del agente limpiados")

async def main():
    """FunciÃ³n principal para ejecutar el agente conversacional"""
    print("ğŸ§  EconomIAssist - Agente Conversacional Modular")
    print("=" * 70)
    print("ğŸš€ Framework: OpenAI Agents SDK + Azure OpenAI GPT-4o-mini")
    print("ğŸ”§ Arquitectura: MCP (Model Context Protocol)")
    print("ğŸ“‹ Basado en: resumeProyect.txt")
    
    # Inicializar agente
    try:
        agent = ConversationalAgent()
        await agent.initialize()
    except Exception as e:
        print(f"âŒ Error inicializando agente: {e}")
        return
    
    print("\nğŸ’¬ Â¡Listo para conversar! (Escribe 'salir' para terminar)")
    print("Ejemplo: 'Â¿CuÃ¡l es mi saldo actual?' o 'ayuda'")
    
    while True:
        try:
            user_input = input("\nğŸ‘¤ Usuario: ").strip()
            
            if user_input.lower() in ['salir', 'exit', 'quit']:
                print("\nğŸ‘‹ Â¡Hasta luego!")
                break
            
            if not user_input:
                continue
            
            # Procesar consulta con el agente
            print("ğŸ¤” Procesando...")
            response = await agent.process_query(user_input)
            print(f"\nğŸ¤– **EconomIAssist:** {response}")
            
        except KeyboardInterrupt:
            print("\nğŸ‘‹ Â¡Hasta luego!")
            break
        except Exception as e:
            print(f"\nâŒ Error: {e}")

if __name__ == "__main__":
    asyncio.run(main())