#!/usr/bin/env python3
"""
Agente Conversacional Modular - OpenAI Agents SDK con MCP Real
Implementaci√≥n completa con conexi√≥n real a servidores MCP externos
"""

import asyncio
import os
import sys
import json
import warnings
from typing import Dict, List, Optional, Any
from dataclasses import dataclass
import structlog
from dotenv import load_dotenv

# Suprimir warnings de tracing del OpenAI SDK
warnings.filterwarnings("ignore")
os.environ["OPENAI_LOG_LEVEL"] = "ERROR"

# Forzar recarga de variables de entorno
for key in list(os.environ.keys()):
    if key.startswith('AZURE_OPENAI_') or key.startswith('TAVILY_'):
        del os.environ[key]

# Cargar variables de entorno
env_path = os.path.join(os.path.dirname(__file__), '..', '..', '.env')
load_dotenv(env_path, override=True)

# OpenAI Agents SDK imports
from agents import Agent, Runner
from agents.models.openai_chatcompletions import OpenAIChatCompletionsModel
from openai import AsyncAzureOpenAI

# Importar cliente MCP real
from .mcp_client import MCPManager

# Configurar logging estructurado
logger = structlog.get_logger()

# Suprimir logs de OpenAI durante ejecuci√≥n
import logging
logging.getLogger("openai").setLevel(logging.ERROR)
logging.getLogger("httpx").setLevel(logging.ERROR)

@dataclass
class MCPServerConfig:
    """Configuraci√≥n de un servidor MCP"""
    name: str
    path: str
    description: str
    capabilities: List[str]

class AzureOpenAIConfig:
    """Configuraci√≥n para Azure OpenAI"""
    
    def __init__(self):
        self.api_base = os.getenv("AZURE_OPENAI_API_BASE")
        self.api_key = os.getenv("AZURE_OPENAI_API_KEY")
        self.api_version = os.getenv("AZURE_OPENAI_API_VERSION")
        self.deployment_name = os.getenv("AZURE_OPENAI_DEPLOYMENT_NAME")
        
        if not all([self.api_base, self.api_key, self.api_version, self.deployment_name]):
            raise ValueError("Faltan credenciales de Azure OpenAI en el archivo .env")
        
        print(f"‚úÖ Azure OpenAI configurado:")
        print(f"   üìç Endpoint: {self.api_base}")
        print(f"   ü§ñ Deployment: {self.deployment_name}")
        print(f"   üîë API Version: {self.api_version}")
    
    def create_client(self) -> AsyncAzureOpenAI:
        """Crea un cliente de Azure OpenAI"""
        return AsyncAzureOpenAI(
            azure_endpoint=self.api_base,
            api_key=self.api_key,
            api_version=self.api_version
        )
    
    def create_model(self) -> OpenAIChatCompletionsModel:
        """Crea un modelo OpenAI configurado para Azure"""
        client = self.create_client()
        return OpenAIChatCompletionsModel(
            model=self.deployment_name,  # Usar deployment name correcto
            openai_client=client
        )

class IntentClassifier: ###MAXI WORK HERE
    """Clasificador de intenciones usando NLP para routing"""
    
    INTENT_PATTERNS = {
        'financial_query': [
            'saldo', 'dinero', 'cuenta', 'balance', 'cuanto tengo',
            'estado financiero', 'resumen'
        ],
        'financial_action': [
            'registra', 'anota', 'guarda', 'gasto', 'ingreso', 
            'transaccion', 'pago', 'compra'
        ],
        'rag_query': [
            'consejo', 'como', 'que es', 'explicame', 'ayuda con',
            'informacion', 'aprende', 'ense√±ame'
        ],
        'help': [
            'ayuda', 'help', 'que puedes hacer', 'comandos', 'funciones'
        ],
        'multi_intent': [
            'y tambien', 'ademas', 'despues', 'luego'
        ]
    }
    
    def classify_intent(self, text: str) -> Dict[str, float]:
        """
        Clasifica intenciones con scores de confianza
        Retorna un diccionario con intenci√≥n -> score
        """
        text_lower = text.lower()
        scores = {}
        
        for intent, keywords in self.INTENT_PATTERNS.items():
            score = 0.0
            for keyword in keywords:
                if keyword in text_lower:
                    score += 1.0
            
            # Normalizar por n√∫mero de keywords
            if keywords:
                scores[intent] = score / len(keywords)
        
        # Determinar intenci√≥n principal
        if not scores or max(scores.values()) == 0:
            scores['general'] = 1.0
        
        return scores
    
    def get_primary_intent(self, text: str) -> str:
        """Obtiene la intenci√≥n principal"""
        scores = self.classify_intent(text)
        return max(scores.items(), key=lambda x: x[1])[0]

class CapabilityDiscovery:
    """Discovery autom√°tico de capacidades MCP"""
    
    def __init__(self):
        self.server_configs = [
            MCPServerConfig(
                name="financial",
                path="src/mcp_server/server.py",
                description="Gesti√≥n financiera: transacciones, saldos, res√∫menes",
                capabilities=["registrar_transaccion", "obtener_saldo", "obtener_transacciones"]
            ),
            MCPServerConfig(
                name="rag",
                path="src/mcp_server/rag_server.py", 
                description="Recuperaci√≥n de informaci√≥n y consejos financieros",
                capabilities=["buscar_informacion", "expandir_contexto", "generar_respuesta_contextual"]
            )
        ]
        self.available_servers = {}
    
    async def discover_and_validate(self) -> Dict[str, MCPServerConfig]:
        """Descubre y valida servidores MCP disponibles"""
        print("üîç Iniciando discovery de servidores MCP...")
        
        available = {}
        for config in self.server_configs:
            if os.path.exists(config.path):
                # Para la demo, asumimos que est√°n disponibles si el archivo existe
                available[config.name] = config
                print(f"‚úÖ Servidor encontrado: {config.name}")
            else:
                print(f"‚ùå Servidor no encontrado: {config.path}")
        
        self.available_servers = available
        return available

class RoutingEngine:
    """Motor de enrutamiento inteligente con fallbacks"""
    
    def __init__(self, discovery: CapabilityDiscovery):
        self.discovery = discovery
        self.intent_to_server = {
            'financial_query': ['financial'],
            'financial_action': ['financial'],
            'rag_query': ['rag', 'financial'],  # Fallback a financial si RAG no est√° disponible
            'general': ['rag', 'financial'],   # Intentar RAG primero, luego financial
            'help': None  # Manejado localmente
        }
    
    def route_intent(self, intent: str) -> Optional[str]:
        """
        Enruta una intenci√≥n al servidor apropiado con fallbacks
        """
        server_preferences = self.intent_to_server.get(intent, ['financial'])
        
        if server_preferences is None:
            return None
        
        # Buscar el primer servidor disponible en orden de preferencia
        available_servers = self.discovery.available_servers
        for server_name in server_preferences:
            if server_name in available_servers:
                return server_name
        
        # Fallback final a financial si est√° disponible
        if 'financial' in available_servers:
            return 'financial'
        
        return None

class MemoryManager:
    """Manejo de memoria sem√°ntica y contexto conversacional"""
    
    def __init__(self):
        self.conversation_history = []
        self.context_cache = {}
        self.max_history = 10
    
    def add_interaction(self, user_input: str, agent_response: str, metadata: Dict[str, Any]):
        """A√±ade una interacci√≥n a la memoria"""
        interaction = {
            'timestamp': asyncio.get_event_loop().time(),
            'user_input': user_input,
            'agent_response': agent_response,
            'metadata': metadata
        }
        
        self.conversation_history.append(interaction)
        
        # Mantener solo las √∫ltimas N interacciones
        if len(self.conversation_history) > self.max_history:
            self.conversation_history = self.conversation_history[-self.max_history:]
    
    def get_context_summary(self) -> str:
        """Genera un resumen del contexto conversacional"""
        if not self.conversation_history:
            return "Primera interacci√≥n del usuario."
        
        recent_interactions = self.conversation_history[-3:]  # √öltimas 3 interacciones
        summary = "Contexto reciente:\n"
        
        for i, interaction in enumerate(recent_interactions, 1):
            summary += f"{i}. Usuario: {interaction['user_input'][:100]}...\n"
            summary += f"   Respuesta: {interaction['agent_response'][:100]}...\n"
        
        return summary

class ConversationalAgent:
    """Agente conversacional con capacidades MCP reales"""
    
    def __init__(self):
        self.azure_client = None
        self.openai_model = None
        self.agent = None
        self.runner = None
        self.mcp_manager = None
        self.session_memory = []
        
    async def initialize(self):
        """Inicializa el agente y las conexiones MCP"""
        try:
            # Inicializar Azure OpenAI
            await self._setup_azure_openai()
            
            # Inicializar gestor MCP
            self.mcp_manager = MCPManager()
            
            # Conectar a servidores MCP
            await self._connect_mcp_servers()
            
            # Configurar agente con herramientas MCP
            await self._setup_agent_with_mcp()
            
            logger.info("‚úÖ Agente conversacional inicializado con MCP real")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Error inicializando agente: {e}")
            return False
    
    async def _connect_mcp_servers(self):
        """Conecta a todos los servidores MCP disponibles"""
        # Conectar a Tavily (b√∫squeda web)
        tavily_connected = await self.mcp_manager.connect_tavily_server()
        if tavily_connected:
            logger.info("üåê Servidor Tavily MCP conectado")
        else:
            logger.warning("‚ö†Ô∏è No se pudo conectar al servidor Tavily MCP")
    
    async def _setup_agent_with_mcp(self):
        """Configura el agente con herramientas MCP disponibles"""
        # Obtener herramientas disponibles
        available_tools = await self.mcp_manager.get_available_tools()
        
        # Crear instrucciones del sistema que incluyan las capacidades MCP
        system_instructions = self._build_system_instructions(available_tools)
        
        # Crear agente
        self.agent = Agent(
            model=self.openai_model,
            instructions=system_instructions,
            name="EconomIAssist"
        )
        
        # Runner se usa como m√©todo est√°tico, no se instancia
        self.runner = None

    def _build_system_instructions(self, available_tools: Dict[str, List[str]]) -> str:
        """Construye las instrucciones del sistema incluyendo capacidades MCP"""
        base_instructions = """Eres EconomIAssist, un asistente personal financiero inteligente.

CAPACIDADES PRINCIPALES:
1. üí∞ Gesti√≥n financiera personal
2. üß† Consejos de educaci√≥n financiera  
3. üìä An√°lisis de gastos e ingresos
4. üåê B√∫squeda de informaci√≥n financiera actualizada

PERSONALIDAD:
- Amigable y profesional
- Explicas conceptos financieros de manera simple
- Usas emojis para hacer la conversaci√≥n m√°s amena
- Siempre sugieres mejores pr√°cticas financieras"""

        # Agregar capacidades MCP disponibles
        if available_tools:
            mcp_capabilities = "\n\nCAPACIDADES MCP DISPONIBLES:\n"
            for server, tools in available_tools.items():
                mcp_capabilities += f"üîß {server.upper()}: {', '.join(tools)}\n"
            
            mcp_capabilities += """
CUANDO USAR MCP:
- Si el usuario pregunta sobre informaci√≥n financiera actual, usa b√∫squeda web
- Si necesitas datos actualizados sobre mercados, inversiones, etc.
- Para obtener noticias financieras recientes
- Para buscar informaci√≥n espec√≠fica que no tienes en tu base de conocimiento

IMPORTANTE: Cuando uses herramientas MCP, explica al usuario qu√© est√°s haciendo."""
            
            base_instructions += mcp_capabilities
        
        return base_instructions

    async def _setup_azure_openai(self):
        """Configura Azure OpenAI"""
        try:
            azure_config = AzureOpenAIConfig()
            self.azure_client = azure_config.create_client()
            self.openai_model = azure_config.create_model()
            logger.info("‚úÖ Azure OpenAI configurado correctamente")
        except Exception as e:
            logger.error(f"‚ùå Error configurando Azure OpenAI: {e}")
            raise

    async def process_query(self, user_input: str) -> str:
        """Alias para process_user_input para compatibilidad"""
        return await self.process_user_input(user_input)

    async def process_user_input(self, user_input: str) -> str:
        """
        Procesa la entrada del usuario y devuelve la respuesta del agente.
        
        Args:
            user_input (str): La consulta del usuario
            
        Returns:
            str: La respuesta del agente
        """
        try:
            print(f"ü§ñ Procesando consulta: {user_input}")
            
            # Ejecutar consulta usando OpenAI Agents SDK
            result = await Runner.run(self.agent, user_input)
            response = result.final_output
            
            print(f"‚úÖ Respuesta generada ({len(response)} caracteres)")
            return response
            
        except Exception as e:
            error_msg = f"Error al procesar la consulta: {str(e)}"
            print(f"‚ùå {error_msg}")
            return f"Lo siento, ocurri√≥ un error al procesar tu consulta: {str(e)}"
    
    async def _analyze_if_needs_web_search(self, user_input: str) -> bool:
        """Analiza si la consulta necesita b√∫squeda web"""
        web_keywords = [
            "actual", "actualizado", "reciente", "√∫ltimo", "√∫ltimas", "hoy", "2025",
            "mercado", "precio", "cotizaci√≥n", "noticias", "tendencias", 
            "inversi√≥n", "d√≥lar", "bolsa", "acciones", "cripto"
        ]
        
        user_lower = user_input.lower()
        return any(keyword in user_lower for keyword in web_keywords)
    
    async def _extract_search_query(self, user_input: str) -> str:
        """Extrae una consulta de b√∫squeda optimizada del input del usuario"""
        # Simplificaci√≥n: extraer t√©rminos clave financieros
        financial_terms = []
        
        keywords = ["d√≥lar", "euro", "bitcoin", "acciones", "mercado", "inversi√≥n", 
                   "inflaci√≥n", "tasas", "banco", "finanzas", "ahorro"]
        
        user_lower = user_input.lower()
        for keyword in keywords:
            if keyword in user_lower:
                financial_terms.append(keyword)
        
        if financial_terms:
            return f"{' '.join(financial_terms)} 2025 tendencias financieras"
        else:
            return f"{user_input} finanzas 2025"

    async def cleanup(self):
        """Limpia recursos al finalizar"""
        if self.mcp_manager:
            await self.mcp_manager.disconnect_all()
        logger.info("üßπ Recursos del agente limpiados")

async def main():
    """Funci√≥n principal para ejecutar el agente conversacional"""
    print("üß† EconomIAssist - Agente Conversacional Modular")
    print("=" * 70)
    print("üöÄ Framework: OpenAI Agents SDK + Azure OpenAI GPT-4o-mini")
    print("üîß Arquitectura: MCP (Model Context Protocol)")
    print("üìã Basado en: resumeProyect.txt")
    
    # Inicializar agente
    try:
        agent = ConversationalAgent()
        await agent.initialize()
    except Exception as e:
        print(f"‚ùå Error inicializando agente: {e}")
        return
    
    print("\nüí¨ ¬°Listo para conversar! (Escribe 'salir' para terminar)")
    print("Ejemplo: '¬øCu√°l es mi saldo actual?' o 'ayuda'")
    
    while True:
        try:
            user_input = input("\nüë§ Usuario: ").strip()
            
            if user_input.lower() in ['salir', 'exit', 'quit']:
                print("\nüëã ¬°Hasta luego!")
                break
            
            if not user_input:
                continue
            
            # Procesar consulta con el agente
            print("ü§î Procesando...")
            response = await agent.process_query(user_input)
            print(f"\nü§ñ **EconomIAssist:** {response}")
            
        except KeyboardInterrupt:
            print("\nüëã ¬°Hasta luego!")
            break
        except Exception as e:
            print(f"\n‚ùå Error: {e}")

if __name__ == "__main__":
    asyncio.run(main())